#!/usr/bin/env python3

import argparse
import base64
import hashlib
import json
import os
import pathlib
import shutil
import subprocess
import sys
import tempfile

import kubernetes
import openshift.dynamic
import openshift.dynamic.exceptions
import urllib3
import yaml
from openshift.dynamic.exceptions import NotFoundError

SCRIPT_DIR = sys.path[0] if os.path.isdir(sys.path[0]) else os.path.dirname(sys.path[0])

class ArgumentParser(argparse.ArgumentParser):

    def error(self, message):
        print(sys.argv, file=sys.stderr)
        print(file=sys.stderr)
        super(ArgumentParser, self).error(message)

def str_presenter(dumper, data):
    if isinstance(data, str):
        if '\n' in data:
            return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')

    return dumper.represent_scalar('tag:yaml.org,2002:str', data)

yaml.add_representer(str, str_presenter)

def del_extra_keys(cur, last, new):
    """Delete keys in cur which are neither present in last nor in new, i.e. keys managed by the cluster."""
    if isinstance(cur, dict):
        for key, val in list(cur.items()):
            if last and key in last or new and key in new:
                del_extra_keys(val, last.get(key) if last else None, new.get(key) if new else None)
            else:
                del cur[key]
    elif isinstance(cur, list):
        for i, cur_item in enumerate(cur):
            del_extra_keys(cur_item, last[i] if last and i < len(last) else None, new[i] if new and i < len(new) else None)

def add_default_keys(cur, last):
    """Add keys to cur which are present in last but missing in cur, i.e. keys that contain default values."""
    if isinstance(last, dict):
        for last_key, last_val in list(last.items()):
            if cur and last_key in cur:
                add_default_keys(cur.get(last_key) if cur else None, last_val)
            else:
                cur[last_key] = last_val
    elif isinstance(last, list):
        for i, last_item in enumerate(last):
            add_default_keys(cur[i] if cur and i < len(cur) else None, last_item)


def hash_secret_values(obj):
    if not obj['kind'] == 'Secret':
        return

    for key, value in obj.get('stringData', {}).items():
        if value is not None:
            obj.setdefault('data', {})[key] = base64.b64encode(value.encode('ascii')).decode('ascii')
        else:
            obj.setdefault('data', {})[key] = None
    obj.pop('stringData', None)

    for key, value in obj.get('data', {}).items():
        if value:
            hashed_value = hashlib.sha1(value.encode()).hexdigest()[0:7]
            obj['data'][key] = f"<hashed-{hashed_value}>"


def export_object(dir, obj, new=None):
    try:
        with open(f"{dir}/{obj['kind']}_{obj['metadata']['name']}.yaml", 'x') as file:
            last_applied = json.loads(obj['metadata'].get('annotations', {}).get('kubectl.kubernetes.io/last-applied-configuration', '{}'))
            if last_applied:
                del_extra_keys(obj, last_applied, new)
                add_default_keys(obj, last_applied)
            obj['metadata'].get('annotations', {}).pop('kubectl.kubernetes.io/last-applied-configuration', None)
            obj['metadata'].pop('creationTimestamp', None)
            obj['metadata'].pop('resourceVersion', None)
            obj['metadata'].pop('selfLink', None)
            obj['metadata'].pop('uid', None)
            obj['metadata'].pop('generation', None)
            obj.pop('status', None)
            hash_secret_values(obj)

            yaml.dump(obj, file, default_flow_style=False, width=float("inf"))
    except FileExistsError:
        pass

# Disable SSL warnings: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
urllib3.disable_warnings()

if 'KUBERNETES_PORT' in os.environ:
    kubernetes.config.load_incluster_config()
    namespace = pathlib.Path('/var/run/secrets/kubernetes.io/serviceaccount/namespace').read_text()
else:
    kubernetes.config.load_kube_config()
    _, active_context = kubernetes.config.list_kube_config_contexts()
    namespace = active_context['context']['namespace']
k8s_config = kubernetes.client.Configuration()

parser = ArgumentParser()
parser.add_argument("-n", "--namespace", help="Namespace to diff objects against, defaults to current namespace")
parser.add_argument("-l", "--selector", help="Selector (label query) to add objects to diff in order to detect removed resources, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)")
parser.add_argument("--server", help="OpenShift server to diff against")
parser.add_argument("--token", help="Bearer token for OpenShift authentication")
args = parser.parse_args()
if args.namespace:
    namespace = args.namespace
if args.selector:
    label_selector = args.selector
else:
    label_selector = None
if args.server:
    k8s_config.host = args.server
if args.token:
    k8s_config.api_key = {"authorization": "Bearer " + args.token}

k8s_client = kubernetes.client.api_client.ApiClient(k8s_config)
dyn_client = openshift.dynamic.DynamicClient(k8s_client)

# from kubectl/pkg/cmd/apply/prune.go

pruneResources = [
    "v1/ConfigMap",
    #"v1/Endpoints",
    "v1/Namespace",
	"v1/PersistentVolumeClaim",
	"v1/PersistentVolume",
	#"v1/Pod",
	#"v1/ReplicationController",
	"v1/Secret",
	"v1/Service",
	"batch/v1/Job",
	"batch/v1beta1/CronJob",
	"extensions/v1beta1/Ingress",
	"apps/v1/DaemonSet",
	"apps/v1/Deployment",
	"apps/v1/ReplicaSet",
	"apps/v1/StatefulSet",
    "route.openshift.io/v1/Route",
    "monitoring.coreos.com/v1/Alertmanager",
    "monitoring.coreos.com/v1/Prometheus",
    "monitoring.coreos.com/v1/PrometheusRule",
    "monitoring.coreos.com/v1/ServiceMonitor",
    "build.openshift.io/v1/BuildConfig",
    "apps.openshift.io/v1/DeploymentConfig",
    "image.openshift.io/v1/ImageStream",
    "extensions/v1beta1/NetworkPolicy",
    "networking.k8s.io/v1/NetworkPolicy",
    "authorization.openshift.io/v1/RoleBinding",
    "rbac.authorization.k8s.io/v1/RoleBinding",
    "authorization.openshift.io/v1/Role",
    "rbac.authorization.k8s.io/v1/Role",
]


with tempfile.TemporaryDirectory() as tmpdir:
    os.makedirs(f"{tmpdir}/new", exist_ok=True)
    os.makedirs(f"{tmpdir}/cur", exist_ok=True)
    documents = yaml.safe_load_all(sys.stdin)
    for doc in documents:
        objects = doc.get('items', None) or [doc]
        for obj in objects:
            obj['metadata']['namespace'] = namespace
            if not 'annotations' in obj['metadata']:
                obj['metadata']['annotations'] = {}

            hash_secret_values(obj)

            with open(f"{tmpdir}/new/{obj['kind']}_{obj['metadata']['name']}.yaml", 'w+') as file:
                yaml.dump(obj, file, default_flow_style=False, width=float("inf"))

            try:
                obj_client = dyn_client.resources.get(api_version = obj['apiVersion'], kind = obj['kind'])
                current = obj_client.get(name=obj['metadata']['name'], namespace=namespace, export=True).to_dict()
                export_object(f"{tmpdir}/cur", current, obj)
            except NotFoundError:
                pass

    if label_selector:
        for resource in pruneResources:
            api_version, _, kind = resource.rpartition('/')
            #try:
            objects = dyn_client.resources.get(api_version=api_version, kind=kind).get(namespace=namespace, label_selector=label_selector).to_dict()
            #except openshift.dynamic.exceptions.ResourceNotFoundError:
            #    continue
            for obj in objects['items']:
                #print(f"{obj['kind']}/{obj['metadata']['name']}")
                if obj['metadata'].get('annotations', {}).get('kubectl.kubernetes.io/last-applied-configuration') or obj['metadata'].get('annotations', {}).get('openshift.io/generated-by'):
                    export_object(f"{tmpdir}/cur", obj)


    color_opt = '--color' #if sys.stdout.isatty() else ''
    p = subprocess.Popen(f"cd {tmpdir} && git --no-pager diff --no-index --no-prefix --minimal {color_opt} cur new | {SCRIPT_DIR}/diff-highlight", shell=True)
    p.communicate()
